{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "7c7245f9", "cell_type": "markdown", "source": "\n# \ud83d\udcd8 Text Summarization using Transformers (BART)\n\nWelcome to this project!  \nIn this notebook, we\u2019ll build a **text summarization system** using **BART (Bidirectional and Auto-Regressive Transformers)** from Hugging Face.  \n\nWe\u2019ll go through:  \n1. Loading the dataset  \n2. Preprocessing text  \n3. Fine-tuning a pretrained model  \n4. Evaluating with ROUGE metrics  \n5. Testing on real examples  \n\n---\n", "metadata": {}}, {"id": "b77a97bf", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n# Install dependencies\n!pip install transformers datasets evaluate rouge_score torch --quiet\n", "outputs": []}, {"id": "44195b61", "cell_type": "markdown", "source": "## \ud83d\udd27 Step 1: Import Libraries\nWe\u2019ll use **Hugging Face Transformers** for the model,  \n**datasets** for data, and **evaluate** for metrics like ROUGE.", "metadata": {}}, {"id": "c9ba930f", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nimport torch\nfrom transformers import BartForConditionalGeneration, BartTokenizer, Trainer, TrainingArguments\nfrom datasets import load_dataset\nimport evaluate\nimport numpy as np\n", "outputs": []}, {"id": "b7dffa67", "cell_type": "markdown", "source": "## \ud83d\udcc2 Step 2: Load Dataset\nWe\u2019ll use the **CNN/DailyMail dataset** which pairs news articles with human-written summaries.", "metadata": {}}, {"id": "4d1f92d3", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\ndataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n\nprint(dataset)\nprint(\"Sample keys:\", dataset[\"train\"][0].keys())\nprint(\"\\nArticle preview:\\n\", dataset[\"train\"][0][\"article\"][:500])\nprint(\"\\nReference summary:\\n\", dataset[\"train\"][0][\"highlights\"])\n", "outputs": []}, {"id": "b4ba732b", "cell_type": "markdown", "source": "## \ud83e\udd16 Step 3: Load Pretrained Model & Tokenizer\nWe\u2019ll use **facebook/bart-large-cnn**, a pretrained model specialized for summarization.", "metadata": {}}, {"id": "4084d670", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nmodel_name = \"facebook/bart-large-cnn\"\n\ntokenizer = BartTokenizer.from_pretrained(model_name)\nmodel = BartForConditionalGeneration.from_pretrained(model_name)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel.to(device)\n", "outputs": []}, {"id": "c0aecc93", "cell_type": "markdown", "source": "## \ud83e\uddf9 Step 4: Preprocess Data\nWe need to tokenize both the **input article** and the **target summary**.", "metadata": {}}, {"id": "d8f103f4", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nmax_input_length = 1024\nmax_target_length = 128\n\ndef preprocess_function(examples):\n    inputs = [doc for doc in examples[\"article\"]]\n    targets = [doc for doc in examples[\"highlights\"]]\n    model_inputs = tokenizer(\n        inputs, max_length=max_input_length, truncation=True\n    )\n\n    # Encode the targets directly (no as_target_tokenizer needed in latest transformers)\n    labels = tokenizer(\n        targets, max_length=max_target_length, truncation=True\n    )\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n", "outputs": []}, {"id": "227d1a1a", "cell_type": "markdown", "source": "## \ud83d\udcca Step 5: Define Evaluation Metrics\nWe\u2019ll use **ROUGE** to measure summary quality.", "metadata": {}}, {"id": "bd508b95", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nrouge = evaluate.load(\"rouge\")\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    return {k: round(v * 100, 4) for k, v in result.items()}\n", "outputs": []}, {"id": "972130b5", "cell_type": "markdown", "source": "## \u2699\ufe0f Step 6: Training Setup\nWe\u2019ll fine-tune for **1 epoch** (demo purposes).", "metadata": {}}, {"id": "bce42914", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=1,\n    predict_with_generate=True,\n    logging_dir=\"./logs\",\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"].select(range(2000)),  # subset for demo\n    eval_dataset=tokenized_datasets[\"validation\"].select(range(500)),\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n", "outputs": []}, {"id": "c26e8e90", "cell_type": "markdown", "source": "## \ud83d\ude80 Step 7: Fine-Tune the Model\nThis may take time depending on hardware.", "metadata": {}}, {"id": "6c96b603", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\ntrainer.train()\n", "outputs": []}, {"id": "e5806480", "cell_type": "markdown", "source": "## \ud83d\udcc8 Step 8: Evaluate Model\nWe\u2019ll check ROUGE scores.", "metadata": {}}, {"id": "9e5a3241", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nresults = trainer.evaluate()\nprint(results)\n", "outputs": []}, {"id": "5f05c599", "cell_type": "markdown", "source": "## \ud83d\udcdd Step 9: Test on New Example\nNow let\u2019s test summarization on a sample article.", "metadata": {}}, {"id": "42608e35", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nsample_text = dataset[\"test\"][0][\"article\"]\n\ninputs = tokenizer(sample_text, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n\nsummary_ids = model.generate(\n    inputs[\"input_ids\"], \n    max_length=150, \n    min_length=40, \n    num_beams=4, \n    length_penalty=2.0,\n    early_stopping=True\n)\n\nprint(\"Original Text:\\n\", sample_text[:500], \"...\")\nprint(\"\\nGenerated Summary:\\n\", tokenizer.decode(summary_ids[0], skip_special_tokens=True))\nprint(\"\\nReference Summary:\\n\", dataset[\"test\"][0][\"highlights\"])\n", "outputs": []}, {"id": "7c90fb7f", "cell_type": "markdown", "source": "## \ud83d\udcbe Step 10: Save and Reload Model\nSave the fine-tuned model for reuse or deployment.", "metadata": {}}, {"id": "d66d56d5", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nmodel.save_pretrained(\"./bart-summarizer\")\ntokenizer.save_pretrained(\"./bart-summarizer\")\n\n# Load later\nloaded_model = BartForConditionalGeneration.from_pretrained(\"./bart-summarizer\")\nloaded_tokenizer = BartTokenizer.from_pretrained(\"./bart-summarizer\")\n", "outputs": []}, {"id": "a99df746", "cell_type": "markdown", "source": "\n# \u2705 Conclusion\n- We fine-tuned **BART** for summarization  \n- Evaluated with **ROUGE metrics**  \n- Tested summarization on unseen data  \n- Saved the model for reuse or deployment  \n\nThis project demonstrates an **end-to-end NLP workflow** using modern Transformers \ud83d\ude80\n", "metadata": {}}]}